{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Stock Price Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as pdr\n",
    "import fix_yahoo_finance as yf\n",
    "import datetime\n",
    "\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeClassification(actual):\n",
    "    if actual > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime(2010,1,1)\n",
    "end = datetime.datetime(2019,5,31)\n",
    "df = pdr.get_data_yahoo('AMZN', start=start, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate daily returns\n",
    "df['returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "df['returns'].fillna(0)\n",
    "# calculate daily returns\n",
    "df['returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "df['returns'].fillna(0)\n",
    "df.iloc[:, len(df.columns) - 1] = df.iloc[:, len(df.columns) - 1].apply(computeClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the last column (Y) -1 = down, 1 = up by applying the defined classifier above to the 'returns_final' dataframe\n",
    "df.iloc[:, len(df.columns) - 1] = df.iloc[:, len(df.columns) - 1].apply(computeClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have a complete dataset with a predictable value, the last column “Return” which is either -1 or 1, create the train and test dataset.\n",
    "#Convert float to int so you can slice the dataframe\n",
    "testData = df[-int((len(df) * 0.10)):]\n",
    "#2nd half is forward tested on\n",
    "trainData = df[:-int((len(df) * 0.90))]\n",
    "#1st half is trained on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all inf with nan\n",
    "testData_1 = testData.replace([np.inf, -np.inf], np.nan)\n",
    "trainData_1 = trainData.replace([np.inf, -np.inf], np.nan)\n",
    "#Replace all nans with 0\n",
    "testData_2 = testData_1.fillna(0)\n",
    "trainData_2 = trainData_1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all inf with nan\n",
    "testData_1 = testData.replace([np.inf, -np.inf], np.nan)\n",
    "trainData_1 = trainData.replace([np.inf, -np.inf], np.nan)\n",
    "#Replace all nans with 0\n",
    "testData_2 = testData_1.fillna(0)\n",
    "trainData_2 = trainData_1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is the list of features \n",
    "data_X_train = trainData_2.iloc[:, 0:len(trainData_2.columns) - 1]\n",
    "#Y is the 1 or -1 value to be predicted (as we added this for the last column above using the apply.(computeClassification) function\n",
    "data_Y_train = trainData_2.iloc[:, len(trainData_2.columns) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test dataset\n",
    "data_X_test = testData_2.iloc[:, 0:len(testData_2.columns) - 1]\n",
    "data_Y_test = testData_2.iloc[:, len(testData_2.columns) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "def print_score(clf, data_X_train, data_y_train, data_X_test, data_y_test, train=True):\n",
    "    if train == True:\n",
    "        print(\"Train Result:\\n\")\n",
    "        print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(data_y_train, clf.predict(data_X_train))))\n",
    "        print(\"Classification Report: \\n {}\\n\".format(classification_report(data_y_train, clf.predict(data_X_train))))\n",
    "        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(data_y_train, clf.predict(data_X_train))))\n",
    "        res = cross_val_score(clf, data_X_train, data_y_train, cv=10, scoring='accuracy')\n",
    "        print(\"Average Accuracy: \\t {0:.4f}\".format(np.mean(res)))\n",
    "        print(\"Accuracy SD: \\t\\t {0:.4f}\".format(np.std(res)))\n",
    "    else:\n",
    "        print(\"Test Result:\\n\")\n",
    "        print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(data_y_test, clf.predict(data_X_test))))\n",
    "        print(\"Classification Report: \\n {}\\n\".format(classification_report(data_y_test,clf.predict(data_X_test))))\n",
    "        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(data_y_test, clf.predict(data_X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(data_X_train, data_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score Employing Machine Learning: 0.5536480686695279\n"
     ]
    }
   ],
   "source": [
    "#Predictions is an array containing the predicted values (-1 or 1) for the features in data_X_test.\n",
    "#You can see the prediction accuracy using the method accuracy_score which compares the predicted values versus the expected ones.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predictions = clf.predict(data_X_test)\n",
    "#Predict y based on x_test\n",
    "print(\"Accuracy Score Employing Machine Learning: \" + str(accuracy_score(data_Y_test, y_predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "\n",
      "accuracy score: 0.5342\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.54      0.22      0.31       113\n",
      "           1       0.53      0.83      0.65       121\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       234\n",
      "   macro avg       0.54      0.52      0.48       234\n",
      "weighted avg       0.54      0.53      0.49       234\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 25  88]\n",
      " [ 21 100]]\n",
      "\n",
      "Average Accuracy: \t 0.5137\n",
      "Accuracy SD: \t\t 0.0668\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Training Results\n",
    "print(print_score(clf,data_X_train, data_Y_train, data_X_test, data_Y_test, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "\n",
      "accuracy score: 0.5536\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       104\n",
      "           1       0.55      1.00      0.71       129\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       233\n",
      "   macro avg       0.28      0.50      0.36       233\n",
      "weighted avg       0.31      0.55      0.39       233\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  0 104]\n",
      " [  0 129]]\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Testing Results\n",
    "print(print_score(clf,data_X_train, data_Y_train, data_X_test, data_Y_test, False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
